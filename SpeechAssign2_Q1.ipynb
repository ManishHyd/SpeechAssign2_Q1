{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "G7rQG9swjCgV"
   },
   "outputs": [],
   "source": [
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "p5r0BrQXWTJr",
    "outputId": "14942383-d179-497c-d96a-2fb5112c5796"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "replace /content/malayalam/test_known/audio/844424930309504-1145-m.m4a? [y]es, [n]o, [A]ll, [N]one, [r]ename: A\n"
     ]
    }
   ],
   "source": [
    "!unzip -q \"SpeechAssign2_Q2/malayalam.zip\" -d \"/content\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Xje_w-cRgrIv",
    "outputId": "23b6b747-76ca-4815-d933-fe62a6f25ff6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "replace /content/malayalam/test_data.txt? [y]es, [n]o, [A]ll, [N]one, [r]ename: A\n"
     ]
    }
   ],
   "source": [
    "!unzip -q \"/content/drive/MyDrive/malayalam.zip\" -d \"/content\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "eQcKnhH0iKZf",
    "outputId": "0b614050-73e9-4fa8-f248-8a02fe7e0184"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: s3prl in /usr/local/lib/python3.10/dist-packages (0.4.15)\n",
      "Requirement already satisfied: torchaudio>=0.8.0 in /usr/local/lib/python3.10/dist-packages (from s3prl) (2.2.1+cu121)\n",
      "Requirement already satisfied: torch!=1.10.0,>=1.8.0 in /usr/local/lib/python3.10/dist-packages (from s3prl) (2.2.1+cu121)\n",
      "Requirement already satisfied: tqdm>=4.56.0 in /usr/local/lib/python3.10/dist-packages (from s3prl) (4.66.2)\n",
      "Requirement already satisfied: numpy>=1.21 in /usr/local/lib/python3.10/dist-packages (from s3prl) (1.25.2)\n",
      "Requirement already satisfied: PyYAML>=5.4.1 in /usr/local/lib/python3.10/dist-packages (from s3prl) (6.0.1)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from s3prl) (3.13.4)\n",
      "Requirement already satisfied: omegaconf>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from s3prl) (2.3.0)\n",
      "Requirement already satisfied: setuptools>=65.5.1 in /usr/local/lib/python3.10/dist-packages (from s3prl) (67.7.2)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from s3prl) (2.31.0)\n",
      "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (from s3prl) (4.38.2)\n",
      "Requirement already satisfied: protobuf==3.20.3 in /usr/local/lib/python3.10/dist-packages (from s3prl) (3.20.3)\n",
      "Requirement already satisfied: antlr4-python3-runtime==4.9.* in /usr/local/lib/python3.10/dist-packages (from omegaconf>=2.1.1->s3prl) (4.9.3)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch!=1.10.0,>=1.8.0->s3prl) (4.11.0)\n",
      "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch!=1.10.0,>=1.8.0->s3prl) (1.12)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch!=1.10.0,>=1.8.0->s3prl) (3.3)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch!=1.10.0,>=1.8.0->s3prl) (3.1.3)\n",
      "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch!=1.10.0,>=1.8.0->s3prl) (2023.6.0)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch!=1.10.0,>=1.8.0->s3prl) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch!=1.10.0,>=1.8.0->s3prl) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch!=1.10.0,>=1.8.0->s3prl) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch!=1.10.0,>=1.8.0->s3prl) (8.9.2.26)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch!=1.10.0,>=1.8.0->s3prl) (12.1.3.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch!=1.10.0,>=1.8.0->s3prl) (11.0.2.54)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch!=1.10.0,>=1.8.0->s3prl) (10.3.2.106)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch!=1.10.0,>=1.8.0->s3prl) (11.4.5.107)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch!=1.10.0,>=1.8.0->s3prl) (12.1.0.106)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.19.3 in /usr/local/lib/python3.10/dist-packages (from torch!=1.10.0,>=1.8.0->s3prl) (2.19.3)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch!=1.10.0,>=1.8.0->s3prl) (12.1.105)\n",
      "Requirement already satisfied: triton==2.2.0 in /usr/local/lib/python3.10/dist-packages (from torch!=1.10.0,>=1.8.0->s3prl) (2.2.0)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch!=1.10.0,>=1.8.0->s3prl) (12.4.127)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->s3prl) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->s3prl) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->s3prl) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->s3prl) (2024.2.2)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.19.3 in /usr/local/lib/python3.10/dist-packages (from transformers->s3prl) (0.20.3)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers->s3prl) (24.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers->s3prl) (2023.12.25)\n",
      "Requirement already satisfied: tokenizers<0.19,>=0.14 in /usr/local/lib/python3.10/dist-packages (from transformers->s3prl) (0.15.2)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers->s3prl) (0.4.2)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch!=1.10.0,>=1.8.0->s3prl) (2.1.5)\n",
      "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch!=1.10.0,>=1.8.0->s3prl) (1.3.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install s3prl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "oBF1Rfe9jXoG",
    "outputId": "db4daec1-5c5d-4528-9cd9-24799801594d"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/s3prl/upstream/byol_s/byol_a/common.py:20: UserWarning: torchaudio._backend.set_audio_backend has been deprecated. With dispatcher enabled, this function is no-op. You can remove the function call.\n",
      "  torchaudio.set_audio_backend(\"sox_io\")\n",
      "WARNING:s3prl.upstream.espnet_hubert.expert:ESPnet is not installed, cannot use espnet_hubert upstream\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchaudio\n",
    "from s3prl.nn import S3PRLUpstream\n",
    "import os\n",
    "import numpy as np\n",
    "from scipy.spatial.distance import cdist\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "import soundfile as sf\n",
    "from scipy.spatial.distance import cosine\n",
    "\n",
    "# Set the device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Load the Kathbath Dataset test set\n",
    "test_audio_path = \"/content/malayalam/test_known/audio\"\n",
    "audio_files = sorted(os.listdir(test_audio_path))\n",
    "\n",
    "# Load reference and non-reference pairs from the text file\n",
    "pairs_file = \"/content/malayalam/test_known_data.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "UNivcoFxtuHJ"
   },
   "outputs": [],
   "source": [
    "pairs_file = \"/content/malayalam/test_known_data.txt\"\n",
    "lines = open(pairs_file).read().splitlines()\n",
    "\n",
    "reference_pairs = []\n",
    "non_reference_pairs = []\n",
    "\n",
    "audio_file = set()\n",
    "\n",
    "for line in lines:\n",
    "    parts = line.strip().split(\")\n",
    "    if len(parts) < 3:\n",
    "        # Skip this line if it doesn't have all three parts\n",
    "        continue\n",
    "\n",
    "    label = int(parts[0])\n",
    "    # Transform the paths and remove the numeric directory\n",
    "    ref_path_parts = parts[1].replace(\"/nlsasfs/home/ai4bharat/gramesh/speechteam/e2e_data/pilot4_karya/aug_dc_data_raw/dc_data_clean_wav/malayalam/test_known/audio\", \"/content/malayalam/test_known/audio\").split('/')\n",
    "    ref_path_parts.remove(ref_path_parts[-2])  # Remove the numeric directory\n",
    "    ref_path = '/'.join(ref_path_parts).replace(\".wav\", \".m4a\")\n",
    "\n",
    "    non_ref_path_parts = parts[2].replace(\"/nlsasfs/home/ai4bharat/gramesh/speechteam/e2e_data/pilot4_karya/aug_dc_data_raw/dc_data_clean_wav/malayalam/test_known/audio\", \"/content/malayalam/test_known/audio\").split('/')\n",
    "    non_ref_path_parts.remove(non_ref_path_parts[-2])  # Remove the numeric directory\n",
    "    non_ref_path = '/'.join(non_ref_path_parts).replace(\".wav\", \".m4a\")\n",
    "\n",
    "    if label == 1:\n",
    "        reference_pairs.append((ref_path, non_ref_path))\n",
    "    else:\n",
    "        non_reference_pairs.append((ref_path, non_ref_path))\n",
    "    audio_file.add(ref_path)\n",
    "    audio_file.add(non_ref_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nJy4yP1HvAb8",
    "outputId": "272baeaa-6e61-45d7-cfdf-d95865dcb8a2"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1767"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(audio_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KrlCVgiN6zVf",
    "outputId": "9971eaa3-ad0a-45de-d5d7-058fae7e8eb8"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50000"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nQOuQgTBk2yM",
    "outputId": "50c8a2ca-88f3-4fb5-d8d6-8a9c241e22f7"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/torch/nn/utils/weight_norm.py:28: UserWarning: torch.nn.utils.weight_norm is deprecated in favor of torch.nn.utils.parametrizations.weight_norm.\n",
      "  warnings.warn(\"torch.nn.utils.weight_norm is deprecated in favor of torch.nn.utils.parametrizations.weight_norm.\")\n",
      "/usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:5109: UserWarning: Support for mismatched key_padding_mask and attn_mask is deprecated. Use same type for both instead.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Load the model\n",
    "model = S3PRLUpstream(\"wavlm_large\")\n",
    "model = model.to(device)\n",
    "model.eval()\n",
    "\n",
    "with torch.no_grad():\n",
    "    wavs = torch.randn(2, 16000 * 2).to(device)\n",
    "    wavs_len = torch.LongTensor([16000 * 1, 16000 * 2]).to(device)\n",
    "    all_hs, all_hs_len = model(wavs, wavs_len)\n",
    "\n",
    "for hs, hs_len in zip(all_hs, all_hs_len):\n",
    "    # assert isinstance(hs, torch.FloatTensor)\n",
    "    # assert isinstance(hs_len, torch.LongTensor)\n",
    "\n",
    "    batch_size, max_seq_len, hidden_size = hs.shape\n",
    "    assert hs_len.dim() == 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "oxRqmbsVBKcW",
    "outputId": "474be9bf-3e00-483b-e7e5-1bcf27173bef"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 100, 1024])\n"
     ]
    }
   ],
   "source": [
    "print(hs.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "3G-v-Q32DEGz"
   },
   "outputs": [],
   "source": [
    "audio_file_list = list(audio_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "TirQxP2SC8wr"
   },
   "outputs": [],
   "source": [
    "a = audio_file_list[0]\n",
    "audio,_ = torchaudio.load(a)\n",
    "# model.forward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vsaiyVXkDoZX",
    "outputId": "80ee559b-1e3c-4c95-e491-80e978a9ca3c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([2, 32000]), tensor([16000, 32000], device='cuda:0'))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wavs.shape, wavs_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dj45PQ5NDWEb",
    "outputId": "aeedcb07-576f-49e5-9734-be7637adb67e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 100, 1024])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.forward(wavs,wavs_len)[0][-1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "X87kqO9zfXW3"
   },
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "diction = {}\n",
    "# Function to extract features from audio files\n",
    "def extract_features(model, audio_files):\n",
    "    all_hs = []\n",
    "    all_hs_len = []\n",
    "    for audio_file in tqdm(audio_files, desc=\"Extracting features\"):\n",
    "        # Load audio file and convert to tensor\n",
    "        audio, sample_rate = torchaudio.load(audio_file)\n",
    "        audio = audio.to(device)  # Move audio to the device\n",
    "        # Preprocess audio if needed (e.g., resampling, normalization)\n",
    "        # Reshape audio tensor to match expected dimensions\n",
    "        if audio.dim() == 1:  # If mono-channel audio\n",
    "            audio = audio.unsqueeze(0)  # Add batch dimension\n",
    "        # Compute features from the audio using the model\n",
    "        with torch.no_grad():\n",
    "            hs, _ = model(audio, torch.LongTensor([audio.size(1)]))\n",
    "            # print(hs)\n",
    "            hs = hs[-1].cpu().detach().numpy()\n",
    "            # hs_len = hs_len.cpu()\n",
    "            diction[audio_file] = hs\n",
    "            # all_hs_len.append(hs_len)\n",
    "            del audio\n",
    "    # return all_hs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0U23hWGJ3E4b",
    "outputId": "e8a1b47b-99c2-43c4-ec20-a6eb672e42b3"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  98%|█████████▊| 1725/1767 [19:29<07:19, 10.45s/it]"
     ]
    }
   ],
   "source": [
    "# Extract features for reference pairs\n",
    "extract_features(model, audio_file_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "boVYvAWGGCJ3"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "\n",
    "# Specify the directory path where you want to save the dictionary\n",
    "directory_path = \"/content/drive/MyDrive/SpeechAssign_Q1\"\n",
    "file_name = \"dictionary_data.pkl\"\n",
    "file_path = os.path.join(directory_path, file_name)\n",
    "\n",
    "# Serialize and save the dictionary to the file\n",
    "with open(file_path, \"wb\") as file:\n",
    "    pickle.dump(diction, file)\n",
    "\n",
    "print(\"Dictionary saved successfully to:\", file_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qw1x4o4u5uqW"
   },
   "outputs": [],
   "source": [
    "\n",
    "# Extract features for non-reference pairs\n",
    "non_reference_features, _ = extract_features(model, [non_ref_path for _, non_ref_path in non_reference_pairs])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "E6oitawZy70p"
   },
   "outputs": [],
   "source": [
    "# Compute cosine similarity between reference and non-reference pairs\n",
    "cosine_similarity_scores = []\n",
    "for ref_feature, non_ref_feature in zip(reference_features, non_reference_features):\n",
    "    cosine_similarity = compute_cosine_similarity(ref_feature, non_ref_feature)\n",
    "    cosine_similarity_scores.extend(cosine_similarity)\n",
    "\n",
    "# Create labels (1 for reference pairs, 0 for non-reference pairs)\n",
    "labels = [1] * len(reference_features) + [0] * len(non_reference_features)\n",
    "\n",
    "# Compute ROC curve\n",
    "fpr, tpr, thresholds = roc_curve(labels, cosine_similarity_scores)\n",
    "\n",
    "# Compute EER\n",
    "eer_threshold = thresholds[np.argmin(np.abs(fpr - (1 - tpr)))]\n",
    "eer = fpr[np.argmin(np.abs(fpr - (1 - tpr)))]\n",
    "\n",
    "# Step 2: Report the EER\n",
    "print(\"Equal Error Rate (EER): {:.2f}%\".format(eer * 100))"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
